{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3125911",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mak109/cs6910_assignment2/blob/main/PART%20B/cs6910_assignment2_partB_question1_2_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada2378b",
   "metadata": {
    "id": "e29e87fc"
   },
   "source": [
    "# Loading and Fine-tuning pretrained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5328f31",
   "metadata": {},
   "source": [
    "## 1. Packages and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9a0c3a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T05:09:33.519133Z",
     "iopub.status.busy": "2023-04-29T05:09:33.517060Z",
     "iopub.status.idle": "2023-04-29T05:09:33.538172Z",
     "shell.execute_reply": "2023-04-29T05:09:33.536785Z",
     "shell.execute_reply.started": "2023-04-29T05:09:33.519088Z"
    },
    "id": "c739a581"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import datetime\n",
    "import shutil\n",
    "from zipfile import ZipFile\n",
    "from PIL import Image\n",
    "from inspect import *\n",
    "from matplotlib import gridspec\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,Sequential,regularizers,optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import * \n",
    "autotune = tf.data.AUTOTUNE\n",
    "from functools import reduce\n",
    "import random\n",
    "import uuid\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac0ac82",
   "metadata": {},
   "source": [
    "## 2. UTA-RLDD preprocessed dataset downloaded from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f474bc60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T05:11:39.644141Z",
     "iopub.status.busy": "2023-04-29T05:11:39.643067Z",
     "iopub.status.idle": "2023-04-29T05:13:50.012641Z",
     "shell.execute_reply": "2023-04-29T05:13:50.011201Z",
     "shell.execute_reply.started": "2023-04-29T05:11:39.644097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading uta-rldd-2.zip to /kaggle/working\n",
      "100%|█████████████████████████████████████▉| 2.40G/2.40G [02:04<00:00, 20.2MB/s]\n",
      "100%|██████████████████████████████████████| 2.40G/2.40G [02:04<00:00, 20.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "!mkdir ~/.kaggle\n",
    "!touch ~/.kaggle/kaggle.json\n",
    "#give kaggle username and key to download dataset\n",
    "api_token = {\"username\":\"\",\"key\":\"\"}\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
    "    json.dump(api_token, file)\n",
    "\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!kaggle datasets download -d mak1999/uta-rldd-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "283c467f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T05:13:50.016545Z",
     "iopub.status.busy": "2023-04-29T05:13:50.015340Z",
     "iopub.status.idle": "2023-04-29T05:14:04.876712Z",
     "shell.execute_reply": "2023-04-29T05:14:04.874367Z",
     "shell.execute_reply.started": "2023-04-29T05:13:50.016499Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting all the folders now...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "foldername = 'uta-rldd-2.zip'\n",
    "with ZipFile(foldername, 'r') as z:\n",
    "    print('Extracting all the folders now...')\n",
    "    z.extractall()\n",
    "    print('Done!')\n",
    "os.remove(foldername)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e726a5",
   "metadata": {},
   "source": [
    "## 3. Wandb setup for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "457c0931",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T05:09:43.845595Z",
     "iopub.status.busy": "2023-04-29T05:09:43.844466Z",
     "iopub.status.idle": "2023-04-29T05:09:47.877833Z",
     "shell.execute_reply": "2023-04-29T05:09:47.876662Z",
     "shell.execute_reply.started": "2023-04-29T05:09:43.845552Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "os.environ['WANDB_ENTITY'] = 'ipda526'\n",
    "os.environ['WANDB_PROJECT'] = 'finetune-drowsiness-detection'\n",
    "#wandb key used for storing model in wandb\n",
    "wandb.login(key='')\n",
    "from wandb.keras import WandbCallback,WandbMetricsLogger, WandbModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f2897f",
   "metadata": {},
   "source": [
    "## 4. Model definition and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28586175",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T05:09:47.879877Z",
     "iopub.status.busy": "2023-04-29T05:09:47.879478Z",
     "iopub.status.idle": "2023-04-29T05:09:47.887714Z",
     "shell.execute_reply": "2023-04-29T05:09:47.885024Z",
     "shell.execute_reply.started": "2023-04-29T05:09:47.879811Z"
    },
    "id": "fa298523"
   },
   "outputs": [],
   "source": [
    "image_size = (256,256)\n",
    "num_classes = 3 #0 - awake 1-drowsy 2 - low vigilant\n",
    "train_dir = 'UTA-RLDD/train'\n",
    "val_dir = 'UTA-RLDD/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0535ba64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T05:09:47.890808Z",
     "iopub.status.busy": "2023-04-29T05:09:47.890309Z",
     "iopub.status.idle": "2023-04-29T05:09:47.900134Z",
     "shell.execute_reply": "2023-04-29T05:09:47.898924Z",
     "shell.execute_reply.started": "2023-04-29T05:09:47.890771Z"
    },
    "id": "47ad59e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ConvNeXtBase': <function ConvNeXtBase at 0x7351b6d228c0>, 'ConvNeXtLarge': <function ConvNeXtLarge at 0x7351b6d22950>, 'ConvNeXtSmall': <function ConvNeXtSmall at 0x7351b6d22830>, 'ConvNeXtTiny': <function ConvNeXtTiny at 0x7351b6d227a0>, 'ConvNeXtXLarge': <function ConvNeXtXLarge at 0x7351b6d229e0>, 'DenseNet121': <function DenseNet121 at 0x7351b6d273b0>, 'DenseNet169': <function DenseNet169 at 0x7351b6d27440>, 'DenseNet201': <function DenseNet201 at 0x7351b6d274d0>, 'EfficientNetB0': <function EfficientNetB0 at 0x7351b6d2f0e0>, 'EfficientNetB1': <function EfficientNetB1 at 0x7351b6d2f170>, 'EfficientNetB2': <function EfficientNetB2 at 0x7351b6d2f200>, 'EfficientNetB3': <function EfficientNetB3 at 0x7351b6d2f290>, 'EfficientNetB4': <function EfficientNetB4 at 0x7351b6d2f320>, 'EfficientNetB5': <function EfficientNetB5 at 0x7351b6d2f3b0>, 'EfficientNetB6': <function EfficientNetB6 at 0x7351b6d2f440>, 'EfficientNetB7': <function EfficientNetB7 at 0x7351b6d2f4d0>, 'EfficientNetV2B0': <function EfficientNetV2B0 at 0x7351b6cb7710>, 'EfficientNetV2B1': <function EfficientNetV2B1 at 0x7351b6cb77a0>, 'EfficientNetV2B2': <function EfficientNetV2B2 at 0x7351b6cb7830>, 'EfficientNetV2B3': <function EfficientNetV2B3 at 0x7351b6cb78c0>, 'EfficientNetV2L': <function EfficientNetV2L at 0x7351b6cb7a70>, 'EfficientNetV2M': <function EfficientNetV2M at 0x7351b6cb79e0>, 'EfficientNetV2S': <function EfficientNetV2S at 0x7351b6cb7950>, 'InceptionResNetV2': <function InceptionResNetV2 at 0x7351b6cb7c20>, 'InceptionV3': <function InceptionV3 at 0x7351b6cbe3b0>, 'MobileNet': <function MobileNet at 0x7351b6cbeb90>, 'MobileNetV2': <function MobileNetV2 at 0x7351b6cbef80>, 'MobileNetV3Large': <function MobileNetV3Large at 0x7351b6ccf320>, 'MobileNetV3Small': <function MobileNetV3Small at 0x7351b6ccf290>, 'NASNetLarge': <function NASNetLarge at 0x7351b6cd5320>, 'NASNetMobile': <function NASNetMobile at 0x7351b6cd5290>, 'RegNetX002': <function RegNetX002 at 0x7351b6c8d950>, 'RegNetX004': <function RegNetX004 at 0x7351b6c8d9e0>, 'RegNetX006': <function RegNetX006 at 0x7351b6c8da70>, 'RegNetX008': <function RegNetX008 at 0x7351b6c8db00>, 'RegNetX016': <function RegNetX016 at 0x7351b6c8db90>, 'RegNetX032': <function RegNetX032 at 0x7351b6c8dc20>, 'RegNetX040': <function RegNetX040 at 0x7351b6c8dcb0>, 'RegNetX064': <function RegNetX064 at 0x7351b6c8dd40>, 'RegNetX080': <function RegNetX080 at 0x7351b6c8ddd0>, 'RegNetX120': <function RegNetX120 at 0x7351b6c8de60>, 'RegNetX160': <function RegNetX160 at 0x7351b6c8def0>, 'RegNetX320': <function RegNetX320 at 0x7351b6c8df80>, 'RegNetY002': <function RegNetY002 at 0x7351b6c93050>, 'RegNetY004': <function RegNetY004 at 0x7351b6c930e0>, 'RegNetY006': <function RegNetY006 at 0x7351b6c93170>, 'RegNetY008': <function RegNetY008 at 0x7351b6c93200>, 'RegNetY016': <function RegNetY016 at 0x7351b6c93290>, 'RegNetY032': <function RegNetY032 at 0x7351b6c93320>, 'RegNetY040': <function RegNetY040 at 0x7351b6c933b0>, 'RegNetY064': <function RegNetY064 at 0x7351b6c93440>, 'RegNetY080': <function RegNetY080 at 0x7351b6c934d0>, 'RegNetY120': <function RegNetY120 at 0x7351b6c93560>, 'RegNetY160': <function RegNetY160 at 0x7351b6c935f0>, 'RegNetY320': <function RegNetY320 at 0x7351b6c93680>, 'ResNet101': <function ResNet101 at 0x7351b6cda7a0>, 'ResNet101V2': <function ResNet101V2 at 0x7351b6ce94d0>, 'ResNet152': <function ResNet152 at 0x7351b6cda830>, 'ResNet152V2': <function ResNet152V2 at 0x7351b6ce9b00>, 'ResNet50': <function ResNet50 at 0x7351b6cda710>, 'ResNet50V2': <function ResNet50V2 at 0x7351b6ce9560>, 'ResNetRS101': <function ResNetRS101 at 0x7351b6ce9050>, 'ResNetRS152': <function ResNetRS152 at 0x7351b6ce90e0>, 'ResNetRS200': <function ResNetRS200 at 0x7351b6ce9170>, 'ResNetRS270': <function ResNetRS270 at 0x7351b6ce9200>, 'ResNetRS350': <function ResNetRS350 at 0x7351b6ce9290>, 'ResNetRS420': <function ResNetRS420 at 0x7351b6ce9320>, 'ResNetRS50': <function ResNetRS50 at 0x7351b6ce2f80>, 'VGG16': <function VGG16 at 0x7351b6ce9d40>, 'VGG19': <function VGG19 at 0x7351b6cef170>, 'Xception': <function Xception at 0x7351b6cef560>}\n"
     ]
    }
   ],
   "source": [
    "#Creating dictionary of models based on imagenet \n",
    "model_list = dict()\n",
    "for key,value in getmembers(tf.keras.applications,isfunction):\n",
    "    model_list[key] = value\n",
    "    \n",
    "print(model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbad4d21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T05:09:54.330055Z",
     "iopub.status.busy": "2023-04-29T05:09:54.329676Z",
     "iopub.status.idle": "2023-04-29T05:09:54.339083Z",
     "shell.execute_reply": "2023-04-29T05:09:54.337816Z",
     "shell.execute_reply.started": "2023-04-29T05:09:54.330021Z"
    },
    "id": "94dd721d"
   },
   "outputs": [],
   "source": [
    "#Creating model using pretrained model\n",
    "def CNN(config,augmentation = None):\n",
    "    base_model = model_list[config['model']](input_shape=image_size +(3,),include_top=False,weights='imagenet')\n",
    "    base_model.trainable = True #this is important\n",
    "    if(len(base_model.layers) > config['fine_tune_last']):\n",
    "        for layer in base_model.layers[:-config['fine_tune_last']]:\n",
    "            layer.trainable = False    \n",
    "    global_average_layer = layers.GlobalAveragePooling2D()\n",
    "    prediction_layer = layers.Dense(num_classes,activation='softmax')\n",
    "    inputs = layers.Input((image_size[0],image_size[1],3))\n",
    "    input_rescale=layers.Rescaling(1./255)(inputs)\n",
    "    x = base_model(input_rescale)\n",
    "    x = global_average_layer(x)\n",
    "    x = layers.Dropout(config['dropout'])(x)\n",
    "    outputs = prediction_layer(x)\n",
    "    model = keras.Model(inputs,outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66d3bfc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T05:09:57.059929Z",
     "iopub.status.busy": "2023-04-29T05:09:57.059536Z",
     "iopub.status.idle": "2023-04-29T05:09:59.175221Z",
     "shell.execute_reply": "2023-04-29T05:09:59.173501Z",
     "shell.execute_reply.started": "2023-04-29T05:09:57.059895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "# tf.debugging.set_log_device_placement(True)\n",
    "tf.config.set_soft_device_placement(True)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "321ac615",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T05:09:59.733210Z",
     "iopub.status.busy": "2023-04-29T05:09:59.732739Z",
     "iopub.status.idle": "2023-04-29T05:09:59.761168Z",
     "shell.execute_reply": "2023-04-29T05:09:59.760173Z",
     "shell.execute_reply.started": "2023-04-29T05:09:59.733172Z"
    },
    "id": "2531c39f"
   },
   "outputs": [],
   "source": [
    "def train(config_in = None,checkpointing=False):\n",
    "\n",
    "\n",
    "  #Default parameters\n",
    "\n",
    "    config_ = {\n",
    "    \"model\": 'VGG19',\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"data_augment\": \"True\",\n",
    "    \"dropout\":0.6,\n",
    "    \"batch_size\":64,\n",
    "    \"fine_tune_last\":10,\n",
    "    \"epochs\":5\n",
    "    }\n",
    "\n",
    "    '''Wandb Configs'''\n",
    "    wandb.init(config=config_)\n",
    "    config = wandb.config\n",
    "    #Setting run name for better readability\n",
    "    wandb.run.name = \"model_\"+str(config[\"model\"])+\"bs_\"+str(config[\"batch_size\"])+\"epochs_\"+str(config[\"epochs\"])+\"fine_\"+str(config['fine_tune_last'])\n",
    "    #Removing the temporary train/val dir if existing\n",
    "    shutil.rmtree(train_dir,ignore_errors=True)\n",
    "    shutil.rmtree(val_dir,ignore_errors=True)\n",
    "    x = random.randint(0,4)\n",
    "    #Pick up a random fold and use it for validation and remaining other 4 folds for training\n",
    "    for i in range(5):\n",
    "        if i == x:\n",
    "            print(f'Copying fold {x+1} to val...')\n",
    "            shutil.copytree(f'UTA-RLDD/fold{x+1}','UTA-RLDD/val')\n",
    "        else:\n",
    "            print(f'Copying fold {i+1} to train...')\n",
    "            fold = f'fold{i+1}'\n",
    "            fold_path = os.path.join('UTA-RLDD', fold)\n",
    "            for subdir, dirs, files in os.walk(fold_path):\n",
    "                dest_subdir = subdir.replace(fold, 'train')\n",
    "                if not os.path.exists(dest_subdir):\n",
    "                    os.makedirs(dest_subdir)\n",
    "                for file in files:\n",
    "                    shutil.copy(os.path.join(subdir, file), os.path.join(dest_subdir, file))\n",
    "\n",
    "    print('Done!')\n",
    "    #Data Augmentation\n",
    "    if config[\"data_augment\"] == 'True':\n",
    "        data_generator = ImageDataGenerator(\n",
    "        rotation_range=50, #random rotation between -50(clockwise) to 50(anti-clockwise) degree\n",
    "        brightness_range=(0.2,0.8), \n",
    "        zoom_range=0.3, #zoom in range from [0.7,1.3]\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        width_shift_range=0.1, #Horizontal Shifting as a ratio of width\n",
    "        height_shift_range=0.2,#Vertical Shifting as a ratio of height\n",
    "        data_format='channels_last'\n",
    "#         \n",
    "        )\n",
    "    else:\n",
    "        data_generator = ImageDataGenerator(\n",
    "            data_format='channels_last'\n",
    "        )\n",
    "    #Train set creation after conditional augmentation\n",
    "    train_generator = data_generator.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = image_size,\n",
    "    batch_size = config['batch_size'],\n",
    "    color_mode = 'rgb',\n",
    "    class_mode = 'sparse',\n",
    "    shuffle=True,\n",
    "    seed=123\n",
    "    )\n",
    "    val_generator = ImageDataGenerator(data_format='channels_last').flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size = image_size,\n",
    "        batch_size = config['batch_size'],\n",
    "        color_mode = 'rgb',\n",
    "        class_mode = 'sparse',\n",
    "        shuffle=True,\n",
    "        seed=123\n",
    "    \n",
    "    )\n",
    "    try:\n",
    "        with tf.device('/device:GPU:0'):\n",
    "            #Building Model based on config \n",
    "            model = CNN(config)\n",
    "            #Early Stopping to prevent overfitting\n",
    "            early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',patience=5,start_from_epoch=3)\n",
    "            #Compiling model \n",
    "            model.compile(\n",
    "            optimizer=optimizers.Adam(learning_rate=config[\"learning_rate\"]),\n",
    "            loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy']\n",
    "            )\n",
    "            #For checkpointing default value is False\n",
    "            if checkpointing == True:\n",
    "                current_directory = os.getcwd()\n",
    "                final_directory = os.path.join(current_directory, f'models_{datetime.datetime.now()}')\n",
    "                if not os.path.exists(final_directory):\n",
    "                    os.makedirs(final_directory)\n",
    "                checkpoint_filepath = final_directory\n",
    "                model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                  filepath=checkpoint_filepath,\n",
    "                  save_weights_only=False,\n",
    "                  monitor='val_accuracy',\n",
    "                  mode='max',\n",
    "                  save_best_only=True)\n",
    "                  #Fitting Model\n",
    "                history = model.fit(train_generator,\n",
    "                  validation_data=val_generator,\n",
    "                  epochs=config[\"epochs\"],\n",
    "                  verbose=1,\n",
    "                  # callbacks = [WandbCallback()] #Used with wandb\n",
    "                  callbacks = [early_stop_callback,model_checkpoint_callback] #Custom callback for checkpointing\n",
    "                  )\n",
    "            else:\n",
    "                history = model.fit(train_generator,\n",
    "                  validation_data=val_generator,\n",
    "                  epochs=config[\"epochs\"],\n",
    "                  verbose=1,#WandbMetricsLogger(log_freq=\"epoch\"),\n",
    "                  callbacks = [early_stop_callback,WandbCallback(monitor='val_accuracy',mode='auto')] #Used with wandb\n",
    "                  )\n",
    "            \n",
    "    except RuntimeError as e:\n",
    "          print(e)\n",
    "    wandb.finish()\n",
    "    shutil.rmtree(train_dir,ignore_errors=True)\n",
    "    shutil.rmtree(val_dir,ignore_errors=True)\n",
    "    return history,model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b54da5b",
   "metadata": {},
   "source": [
    "## Standalone Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ce082ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T05:14:04.879369Z",
     "iopub.status.busy": "2023-04-29T05:14:04.878593Z",
     "iopub.status.idle": "2023-04-29T05:44:37.883573Z",
     "shell.execute_reply": "2023-04-29T05:44:37.882453Z",
     "shell.execute_reply.started": "2023-04-29T05:14:04.879319Z"
    },
    "id": "df3d0dc7",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:r8v5sbrc) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">likely-brook-86</strong> at: <a href='https://wandb.ai/ipda526/finetune-drowsiness-detection/runs/r8v5sbrc' target=\"_blank\">https://wandb.ai/ipda526/finetune-drowsiness-detection/runs/r8v5sbrc</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230429_051002-r8v5sbrc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:r8v5sbrc). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20230429_051404-beo7mtw5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ipda526/finetune-drowsiness-detection/runs/beo7mtw5' target=\"_blank\">graceful-spaceship-87</a></strong> to <a href='https://wandb.ai/ipda526/finetune-drowsiness-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ipda526/finetune-drowsiness-detection' target=\"_blank\">https://wandb.ai/ipda526/finetune-drowsiness-detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ipda526/finetune-drowsiness-detection/runs/beo7mtw5' target=\"_blank\">https://wandb.ai/ipda526/finetune-drowsiness-detection/runs/beo7mtw5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying fold 1 to train...\n",
      "Copying fold 2 to train...\n",
      "Copying fold 3 to val...\n",
      "Copying fold 4 to train...\n",
      "Copying fold 5 to train...\n",
      "Done!\n",
      "Found 7986 images belonging to 3 classes.\n",
      "Found 2160 images belonging to 3 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80134624/80134624 [==============================] - 4s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/backend.py:5586: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits, \"Softmax\", \"sparse_categorical_crossentropy\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - ETA: 0s - loss: 1.1070 - accuracy: 0.3343"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/kaggle/working/wandb/run-20230429_051404-beo7mtw5/files/model-best)... Done. 1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 362s 3s/step - loss: 1.1070 - accuracy: 0.3343 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 2/5\n",
      "125/125 [==============================] - ETA: 0s - loss: 1.0987 - accuracy: 0.3385"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/kaggle/working/wandb/run-20230429_051404-beo7mtw5/files/model-best)... Done. 1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 339s 3s/step - loss: 1.0987 - accuracy: 0.3385 - val_loss: 1.0987 - val_accuracy: 0.3593\n",
      "Epoch 3/5\n",
      "125/125 [==============================] - 331s 3s/step - loss: 1.0986 - accuracy: 0.3361 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 4/5\n",
      "125/125 [==============================] - 333s 3s/step - loss: 1.0985 - accuracy: 0.3423 - val_loss: 1.0986 - val_accuracy: 0.3333\n",
      "Epoch 5/5\n",
      "125/125 [==============================] - 332s 3s/step - loss: 1.0986 - accuracy: 0.3393 - val_loss: 1.0986 - val_accuracy: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▅▃█▅</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>loss</td><td>█▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁█▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▅▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.33934</td></tr><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_accuracy</td><td>0.35926</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>loss</td><td>1.09858</td></tr><tr><td>val_accuracy</td><td>0.33333</td></tr><tr><td>val_loss</td><td>1.09862</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">graceful-spaceship-87</strong> at: <a href='https://wandb.ai/ipda526/finetune-drowsiness-detection/runs/beo7mtw5' target=\"_blank\">https://wandb.ai/ipda526/finetune-drowsiness-detection/runs/beo7mtw5</a><br/>Synced 6 W&B file(s), 1 media file(s), 10 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230429_051404-beo7mtw5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history,model = train()\n",
    "#Visualization part\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "# plt.savefig('metrics.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1ef82e",
   "metadata": {},
   "source": [
    "## Wandb integration for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d946b3f2",
   "metadata": {
    "id": "QfDuh5aysXsg"
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "'''Wandb Sweeps'''\n",
    "sweep_config = {\n",
    "  \"name\" : \"best-sweep-finetune-kaggle\"+str(uuid.uuid1()),\n",
    "  \"method\" : \"bayes\",\n",
    "  \"metric\" : {\n",
    "      \"name\" : \"val_accuracy\",\n",
    "      \"goal\" : \"maximize\"\n",
    "  },\n",
    "  \n",
    "  \"parameters\" : {\n",
    "      \"model\" : {\n",
    "          \"values\" : [\"InceptionV3\", \"InceptionResNetV2\",\"Xception\",\"ResNet50\",\"MobileNetV2\"]\n",
    "      },\n",
    "\n",
    "  \"learning_rate\" :{\n",
    "      \"values\" : [1e-3,1e-4]\n",
    "  },\n",
    "  \"data_augment\" : {\n",
    "      \"values\" : [\"True\",\"False\"]\n",
    "  },\n",
    "  \"dropout\" : {\n",
    "      \"values\" : [0.2,0.3,0.4]\n",
    "  },\n",
    "\n",
    "  \"batch_size\" : {\n",
    "      \"values\" : [32,64]\n",
    "  },\n",
    "  \"fine_tune_last\" : {\n",
    "  \"values\" : [0,10,20,30]\n",
    "  },\n",
    "    \"epochs\" : {\n",
    "      \"values\" : [5,10,15,20]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "sweep_id=wandb.sweep(sweep_config,entity=\"ipda526\",project=\"finetune-drowsiness-detection\")\n",
    "wandb.agent(sweep_id, function=train, count=10) # For ten runs"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "cs6910_assignment2_partB_question1_2_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
