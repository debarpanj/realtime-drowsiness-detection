{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13a94e09",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mak109/cs6910_assignment2/blob/main/PART%20A/cs6910_assignment2_partA_question1_2_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6567fb61",
   "metadata": {
    "id": "mdhEiMuqlUwE"
   },
   "source": [
    "# Training CNN from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e9541f",
   "metadata": {},
   "source": [
    "## 1. Packages and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73afa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "from PIL import Image\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,Sequential,regularizers,optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import random\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cc2f9b",
   "metadata": {},
   "source": [
    "## 2. UTA-RLDD preprocessed dataset downloaded from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5f519d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T20:01:03.444228Z",
     "iopub.status.busy": "2023-04-28T20:01:03.443879Z",
     "iopub.status.idle": "2023-04-28T20:02:49.973694Z",
     "shell.execute_reply": "2023-04-28T20:02:49.972293Z",
     "shell.execute_reply.started": "2023-04-28T20:01:03.444189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
      "Downloading uta-rldd.zip to /kaggle/working\n",
      "100%|██████████████████████████████████████| 2.40G/2.40G [01:41<00:00, 33.6MB/s]\n",
      "100%|██████████████████████████████████████| 2.40G/2.40G [01:41<00:00, 25.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "!mkdir ~/.kaggle\n",
    "!touch ~/.kaggle/kaggle.json\n",
    "api_token = {\"username\":\"\",\"key\":\"\"} #Place your kaggle credentials here\n",
    "\n",
    "import json\n",
    "\n",
    "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
    "    json.dump(api_token, file)\n",
    "\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!kaggle datasets download -d mak1999/uta-rldd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e099e35f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-04-28T20:02:56.654062Z",
     "iopub.status.busy": "2023-04-28T20:02:56.653313Z",
     "iopub.status.idle": "2023-04-28T20:03:15.271156Z",
     "shell.execute_reply": "2023-04-28T20:03:15.269885Z",
     "shell.execute_reply.started": "2023-04-28T20:02:56.654021Z"
    },
    "id": "7b44f191",
    "outputId": "4f26ac19-0cbe-4ba3-b549-615ed1fa2c5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting all the files now...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "filename = 'uta-rldd.zip'\n",
    "with ZipFile(filename, 'r') as z:\n",
    "    print('Extracting all the files now...')\n",
    "    z.extractall()\n",
    "    print('Done!')\n",
    "os.remove(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a117832c",
   "metadata": {},
   "source": [
    "## 3. Wandb setup for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be4cfbe4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T20:03:32.206552Z",
     "iopub.status.busy": "2023-04-28T20:03:32.205348Z",
     "iopub.status.idle": "2023-04-28T20:03:35.330704Z",
     "shell.execute_reply": "2023-04-28T20:03:35.329468Z",
     "shell.execute_reply.started": "2023-04-28T20:03:32.206510Z"
    },
    "id": "57958201"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdebarpanjana213\u001b[0m (\u001b[33mipda526\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "os.environ['WANDB_ENTITY'] = 'ipda526'\n",
    "os.environ['WANDB_PROJECT'] = 'baseline-drowsiness-detection'\n",
    "wandb.login(key='') #Place your wandb api key here\n",
    "from wandb.keras import WandbCallback,WandbMetricsLogger, WandbModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9d6e474",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T20:03:45.055815Z",
     "iopub.status.busy": "2023-04-28T20:03:45.054775Z",
     "iopub.status.idle": "2023-04-28T20:03:45.997820Z",
     "shell.execute_reply": "2023-04-28T20:03:45.996681Z",
     "shell.execute_reply.started": "2023-04-28T20:03:45.055771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "# tf.debugging.set_log_device_placement(True)\n",
    "tf.config.set_soft_device_placement(True)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed224f5e",
   "metadata": {},
   "source": [
    "## 4. Model definition and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f5a7684",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T20:03:52.296649Z",
     "iopub.status.busy": "2023-04-28T20:03:52.296121Z",
     "iopub.status.idle": "2023-04-28T20:03:52.302103Z",
     "shell.execute_reply": "2023-04-28T20:03:52.300853Z",
     "shell.execute_reply.started": "2023-04-28T20:03:52.296608Z"
    },
    "id": "fa298523"
   },
   "outputs": [],
   "source": [
    "image_size = (256,256)\n",
    "num_layers = 4 #Number of convolution layers\n",
    "num_classes = 3 #0 - awake 1-drowsy 2 - low vigilant\n",
    "train_dir = 'uta-rldd/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9c24085",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T20:04:03.576912Z",
     "iopub.status.busy": "2023-04-28T20:04:03.576167Z",
     "iopub.status.idle": "2023-04-28T20:04:03.589079Z",
     "shell.execute_reply": "2023-04-28T20:04:03.587918Z",
     "shell.execute_reply.started": "2023-04-28T20:04:03.576871Z"
    },
    "id": "fb1b05f7"
   },
   "outputs": [],
   "source": [
    "def CNN(config):\n",
    "    model = Sequential([\n",
    "        layers.Input((image_size[0],image_size[1],3)),\n",
    "        layers.Rescaling(1./255)\n",
    "        ])\n",
    "    \n",
    "    for l in range(num_layers):\n",
    "        model.add(layers.Conv2D(filters=config[\"filters_list\"][l],kernel_size=(config[\"kernel_sizes\"][l][0],config[\"kernel_sizes\"][l][1]),\n",
    "                        activation=config[\"activation\"],padding=\"same\",kernel_regularizer=regularizers.l2(config[\"weight_decay\"])))\n",
    "        if config[\"batch_normalization\"] == 'True':\n",
    "            model.add(layers.BatchNormalization())\n",
    "        model.add(layers.MaxPooling2D())\n",
    "        if(l<3):model.add(layers.Dropout(config['dropout']))\n",
    "            \n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(config[\"dense_layer_size\"],activation=config[\"activation\"],kernel_regularizer=regularizers.l2(config[\"weight_decay\"])))\n",
    "    model.add(layers.Dropout(config['dropout']))\n",
    "    model.add(layers.Dense(config[\"dense_layer_size\"]/2,activation=config[\"activation\"],kernel_regularizer=regularizers.l2(config[\"weight_decay\"])))\n",
    "\n",
    "    model.add(layers.Dense(num_classes,activation=\"softmax\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c832f98f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T20:04:09.309145Z",
     "iopub.status.busy": "2023-04-28T20:04:09.308712Z",
     "iopub.status.idle": "2023-04-28T20:04:09.328057Z",
     "shell.execute_reply": "2023-04-28T20:04:09.326892Z",
     "shell.execute_reply.started": "2023-04-28T20:04:09.309108Z"
    },
    "id": "537a926a"
   },
   "outputs": [],
   "source": [
    "#Training goes here\n",
    "#Comment out the code related to Wandb if training is done without wandb integration\n",
    "def train(config_in=None,checkpointing=False):\n",
    "    #default configuration\n",
    "    config_ = {\n",
    "    \"kernel_sizes\" : [(3,3),(5,5),(7,7),(9,9)],\n",
    "    \"activation\" : 'relu',\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"filters_list\" : [16,32,64,128],\n",
    "    \"dense_layer_size\" : 128,\n",
    "    \"batch_normalization\": \"True\",\n",
    "    \"data_augment\": \"False\",\n",
    "    \"weight_decay\":0.0005,\n",
    "    \"dropout\":0.2,\n",
    "    \"batch_size\":64,\n",
    "    \"epochs\":5\n",
    "    }\n",
    "    if config_in is not None:\n",
    "          config = config_in\n",
    "    else:\n",
    "          config = config_ #Default Config\n",
    "\n",
    "    '''Wandb Configs'''\n",
    "    wandb.init(config=config_)\n",
    "    config = wandb.config\n",
    "    #Setting run name for better readability\n",
    "    wandb.run.name = \"nd_\"+str(config[\"dense_layer_size\"])+\"bs_\"+str(config[\"batch_size\"])+\"ac_\"+str(config[\"activation\"])\n",
    "    #Some data preprocessing and train,val splitting\n",
    "    \n",
    "    #Data Augmentation This can also be validated for better results\n",
    "    if config[\"data_augment\"] == 'True':\n",
    "        data_generator = ImageDataGenerator(\n",
    "        rotation_range=50, #random rotation between -50(clockwise) to 50(anti-clockwise) degree\n",
    "        brightness_range=(0.2,0.8), \n",
    "        zoom_range=0.3, #zoom in range from [0.7,1.3]\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        width_shift_range=0.1, #Horizontal Shifting as a ratio of width\n",
    "        height_shift_range=0.2,#Vertical Shifting as a ratio of height\n",
    "        data_format='channels_last',\n",
    "        validation_split=0.1\n",
    "#         dtype=tf.float32\n",
    "        )\n",
    "    else:\n",
    "        data_generator = ImageDataGenerator(\n",
    "            data_format='channels_last',\n",
    "            validation_split=0.1\n",
    "#             dtype=tf.float32\n",
    "        )\n",
    "    #Train set creation after conditional augmentation\n",
    "    train_generator = data_generator.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = image_size,\n",
    "    batch_size = config['batch_size'],\n",
    "    color_mode = 'rgb',\n",
    "    class_mode = 'sparse',\n",
    "    shuffle=True,\n",
    "    subset='training',\n",
    "    seed=123\n",
    "    )\n",
    "    val_generator = ImageDataGenerator(validation_split=0.1,data_format='channels_last').flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size = image_size,\n",
    "        batch_size = config['batch_size'],\n",
    "        color_mode = 'rgb',\n",
    "        class_mode = 'sparse',\n",
    "        shuffle=True,\n",
    "        subset='validation',\n",
    "        seed=123\n",
    "    \n",
    "    )\n",
    "    try:\n",
    "        with tf.device('/device:GPU:0'):\n",
    "            #Building Model based on config \n",
    "            model = CNN(config)\n",
    "\n",
    "            #Compiling model \n",
    "            model.compile(\n",
    "            optimizer=optimizers.Adam(learning_rate=config[\"learning_rate\"]),\n",
    "            loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy']\n",
    "            )\n",
    "            #For checkpointing default value is False\n",
    "            if checkpointing == True:\n",
    "                current_directory = os.getcwd()\n",
    "                final_directory = os.path.join(current_directory, f'models_{datetime.datetime.now()}')\n",
    "                if not os.path.exists(final_directory):\n",
    "                    os.makedirs(final_directory)\n",
    "                checkpoint_filepath = final_directory\n",
    "                model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                  filepath=checkpoint_filepath,\n",
    "                  save_weights_only=False,\n",
    "                  monitor='val_accuracy',\n",
    "                  mode='max',\n",
    "                  save_best_only=True)\n",
    "                  #Fitting Model\n",
    "                history = model.fit(train_generator,\n",
    "                  validation_data=val_generator,\n",
    "                  epochs=config[\"epochs\"],\n",
    "                  verbose=1,\n",
    "                  # callbacks = [WandbCallback()] #Used with wandb\n",
    "                  callbacks = [model_checkpoint_callback] #Custom callback for checkpointing\n",
    "                  )\n",
    "            else:\n",
    "                history = model.fit(train_generator,\n",
    "                  validation_data=val_generator,\n",
    "                  epochs=config[\"epochs\"],\n",
    "                  verbose=1,#WandbMetricsLogger(log_freq=\"epoch\"),\n",
    "                  callbacks = [WandbCallback(monitor='val_accuracy',mode='auto'),\n",
    "                               WandbModelCheckpoint(filepath=\"models\",monitor='val_accuracy',verbose=1,save_freq='epoch',mode='max')] #Used with wandb\n",
    "                  )\n",
    "            wandb.finish()\n",
    "    except RuntimeError as e:\n",
    "          print(e)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155b4e7a",
   "metadata": {},
   "source": [
    "## Standalone training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83218b5d",
   "metadata": {
    "id": "mG9a2xQtg1-u",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = train()\n",
    "#Visualization part\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "# plt.savefig('metrics.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b247db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2a867b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T20:04:14.627935Z",
     "iopub.status.busy": "2023-04-28T20:04:14.626877Z",
     "iopub.status.idle": "2023-04-28T21:04:05.600028Z",
     "shell.execute_reply": "2023-04-28T21:04:05.598518Z",
     "shell.execute_reply.started": "2023-04-28T20:04:14.627886Z"
    },
    "id": "5d023074"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 814fswy2\n",
      "Sweep URL: https://wandb.ai/ipda526/baseline-drowsiness-detection/sweeps/814fswy2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xvsgsoxm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: gelu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normalization: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augment: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters_list: [32, 64, 128, 256]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_sizes: [[5, 5], [5, 5], [5, 5], [5, 5]]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0005\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20230428_200418-xvsgsoxm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ipda526/baseline-drowsiness-detection/runs/xvsgsoxm' target=\"_blank\">confused-sweep-1</a></strong> to <a href='https://wandb.ai/ipda526/baseline-drowsiness-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/ipda526/baseline-drowsiness-detection/sweeps/814fswy2' target=\"_blank\">https://wandb.ai/ipda526/baseline-drowsiness-detection/sweeps/814fswy2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ipda526/baseline-drowsiness-detection' target=\"_blank\">https://wandb.ai/ipda526/baseline-drowsiness-detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ipda526/baseline-drowsiness-detection/sweeps/814fswy2' target=\"_blank\">https://wandb.ai/ipda526/baseline-drowsiness-detection/sweeps/814fswy2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ipda526/baseline-drowsiness-detection/runs/xvsgsoxm' target=\"_blank\">https://wandb.ai/ipda526/baseline-drowsiness-detection/runs/xvsgsoxm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9132 images belonging to 3 classes.\n",
      "Found 1014 images belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/backend.py:5586: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits, \"Softmax\", \"sparse_categorical_crossentropy\"\n",
      "2023-04-28 20:04:56.311521: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - ETA: 0s - loss: 1.8760 - accuracy: 0.7032"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/kaggle/working/wandb/run-20230428_200418-xvsgsoxm/files/model-best)... Done. 0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 239s 2s/step - loss: 1.8760 - accuracy: 0.7032 - val_loss: 9.8384 - val_accuracy: 0.3955\n",
      "Epoch 2/30\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.7314 - accuracy: 0.8581"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/kaggle/working/wandb/run-20230428_200418-xvsgsoxm/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: saving model to models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 228s 2s/step - loss: 0.7314 - accuracy: 0.8581 - val_loss: 9.1543 - val_accuracy: 0.4014\n",
      "Epoch 3/30\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.6345 - accuracy: 0.8928"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/kaggle/working/wandb/run-20230428_200418-xvsgsoxm/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: saving model to models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 227s 2s/step - loss: 0.6345 - accuracy: 0.8928 - val_loss: 8.1566 - val_accuracy: 0.5138\n",
      "Epoch 4/30\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.5830 - accuracy: 0.9079\n",
      "Epoch 4: saving model to models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 222s 2s/step - loss: 0.5830 - accuracy: 0.9079 - val_loss: 6.2556 - val_accuracy: 0.4043\n",
      "Epoch 5/30\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.5707 - accuracy: 0.9201\n",
      "Epoch 5: saving model to models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 222s 2s/step - loss: 0.5707 - accuracy: 0.9201 - val_loss: 5.6838 - val_accuracy: 0.4290\n",
      "Epoch 6/30\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.4650 - accuracy: 0.9466"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/kaggle/working/wandb/run-20230428_200418-xvsgsoxm/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6: saving model to models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 227s 2s/step - loss: 0.4650 - accuracy: 0.9466 - val_loss: 6.2944 - val_accuracy: 0.5207\n",
      "Epoch 7/30\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.4205 - accuracy: 0.9506"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/kaggle/working/wandb/run-20230428_200418-xvsgsoxm/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7: saving model to models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 228s 2s/step - loss: 0.4205 - accuracy: 0.9506 - val_loss: 3.7917 - val_accuracy: 0.5947\n",
      "Epoch 8/30\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.5214 - accuracy: 0.9320\n",
      "Epoch 8: saving model to models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 223s 2s/step - loss: 0.5214 - accuracy: 0.9320 - val_loss: 11.1693 - val_accuracy: 0.4034\n",
      "Epoch 9/30\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.4804 - accuracy: 0.9489\n",
      "Epoch 9: saving model to models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 222s 2s/step - loss: 0.4804 - accuracy: 0.9489 - val_loss: 6.7197 - val_accuracy: 0.3511\n",
      "Epoch 10/30\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.4776 - accuracy: 0.9506\n",
      "Epoch 10: saving model to models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 224s 2s/step - loss: 0.4776 - accuracy: 0.9506 - val_loss: 3.8859 - val_accuracy: 0.5227\n",
      "Epoch 11/30\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.5197 - accuracy: 0.9478\n",
      "Epoch 11: saving model to models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 243s 2s/step - loss: 0.5197 - accuracy: 0.9478 - val_loss: 6.2075 - val_accuracy: 0.4842\n",
      "Epoch 12/30\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.4480 - accuracy: 0.9611"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/kaggle/working/wandb/run-20230428_200418-xvsgsoxm/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12: saving model to models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 228s 2s/step - loss: 0.4480 - accuracy: 0.9611 - val_loss: 4.2165 - val_accuracy: 0.6243\n",
      "Epoch 13/30\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.3820 - accuracy: 0.9685"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/kaggle/working/wandb/run-20230428_200418-xvsgsoxm/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13: saving model to models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 229s 2s/step - loss: 0.3820 - accuracy: 0.9685 - val_loss: 2.6988 - val_accuracy: 0.6371\n",
      "Epoch 14/30\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.3488 - accuracy: 0.9723\n",
      "Epoch 14: saving model to models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 224s 2s/step - loss: 0.3488 - accuracy: 0.9723 - val_loss: 4.7458 - val_accuracy: 0.4359\n",
      "Epoch 15/30\n",
      "143/143 [==============================] - ETA: 0s - loss: 0.3114 - accuracy: 0.9732\n",
      "Epoch 15: saving model to models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./models)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 223s 2s/step - loss: 0.3114 - accuracy: 0.9732 - val_loss: 12.3624 - val_accuracy: 0.3491\n",
      "Epoch 16/30\n",
      " 10/143 [=>............................] - ETA: 2:58 - loss: 0.3851 - accuracy: 0.9547"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a200175e73485399e00db18350fe59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1400.951 MB of 1400.951 MB uploaded (0.794 MB deduped)\\r'), FloatProgress(value=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▅▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>loss</td><td>█▃▂▂▂▂▁▂▂▂▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▂▂▅▂▃▅▇▂▁▅▄██▃▁</td></tr><tr><td>val_loss</td><td>▆▆▅▄▃▄▂▇▄▂▄▂▁▂█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.97317</td></tr><tr><td>best_epoch</td><td>12</td></tr><tr><td>best_val_accuracy</td><td>0.63708</td></tr><tr><td>epoch</td><td>14</td></tr><tr><td>loss</td><td>0.31139</td></tr><tr><td>val_accuracy</td><td>0.34911</td></tr><tr><td>val_loss</td><td>12.36236</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">confused-sweep-1</strong> at: <a href='https://wandb.ai/ipda526/baseline-drowsiness-detection/runs/xvsgsoxm' target=\"_blank\">https://wandb.ai/ipda526/baseline-drowsiness-detection/runs/xvsgsoxm</a><br/>Synced 6 W&B file(s), 1 media file(s), 110 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230428_200418-xvsgsoxm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import uuid\n",
    "'''Wandb Sweeps '''\n",
    "#Sweep configuration for runs\n",
    "sweep_config = {\n",
    "  \"name\" : \"best-sweep-kaggle\"+str(uuid.uuid1()),\n",
    "  \"method\" : \"bayes\",\n",
    "  \"metric\" : {\n",
    "      \"name\" : \"val_accuracy\",\n",
    "      \"goal\" : \"maximize\"\n",
    "  },\n",
    "  \"parameters\" : {\n",
    "    \"epochs\" : {\n",
    "      \"values\" : [10,20,30]\n",
    "    },\n",
    "    \"learning_rate\" :{\n",
    "      \"values\" : [1e-3,1e-4]\n",
    "    },\n",
    "    \"kernel_sizes\":{\n",
    "        \"values\" : [[(3,3),(3,3),(3,3),(3,3)],\n",
    "                    [(3,3),(3,3),(5,5),(7,7)],\n",
    "                    [(11,11),(11,11),(7,7),(5,5)],\n",
    "                    [(3,3),(5,5),(7,7),(9,9)],\n",
    "                    [(5,5),(5,5),(5,5),(5,5)]]\n",
    "    },\n",
    "    \"filters_list\":{\n",
    "        \"values\" : [[32,32,32,32],[256,128,64,32],[32,64,64,128],[32,64,128,256],[64,32,64,32]]\n",
    "    },\n",
    "    \"weight_decay\":{\n",
    "      \"values\": [0,0.0005,0.005]  \n",
    "    },\n",
    "    \"data_augment\":{\n",
    "        \"values\": [\"True\",\"False\"]\n",
    "    },\n",
    "    \"batch_size\":{\n",
    "        \"values\":[32,64]\n",
    "    },\n",
    "    \"activation\":{\n",
    "        \"values\": [\"relu\",\"elu\",\"swish\",\"gelu\"]\n",
    "    },\n",
    "      \"dropout\":{\n",
    "          \"values\":[0.0,0.2,0.4]\n",
    "      },\n",
    "      \"dense_layer_size\":{\n",
    "          \"values\":[64,128,256,512]\n",
    "      },\n",
    "      \"batch_normalization\":{\n",
    "          \"values\":[\"True\",\"False\"]\n",
    "      }\n",
    "  }\n",
    "}\n",
    "sweep_id=wandb.sweep(sweep_config,entity=\"ipda526\",project=\"baseline-drowsiness-detection\")\n",
    "wandb.agent(sweep_id, function=train, count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e82c5b5",
   "metadata": {
    "id": "kNQX6n7Ij_mF"
   },
   "outputs": [],
   "source": [
    "'''This section is used for loading the models saved with datetime when checkpointing is True'''\n",
    "# #This can be used when checkpointing is set to True and models are saved in model directory with proper name in the current working directory\n",
    "# model_dir = 'models_2022-04-03 00:00:29.823768' #model director name goes here\n",
    "# new_model = tf.keras.models.load_model(model_dir)\n",
    "# # Check its architecture\n",
    "# new_model.summary()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "cs6910_assignment2_partA_question1_2_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
